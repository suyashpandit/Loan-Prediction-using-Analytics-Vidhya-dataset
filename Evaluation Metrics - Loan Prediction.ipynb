{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96599e6-0a12-4b2d-9547-2884bdd0cca8",
   "metadata": {},
   "source": [
    "\n",
    " **EVALUATION METRICS**\n",
    " \n",
    "**K-fold cross validation results:** Accuracy 86% , Precision 0.84 , Recall 1.00 , F-1 Score 0.91\n",
    "\n",
    " Recall - model identified all positive cases as positive \n",
    " Precision - Of the loans that model predicted as positive, 84 percent were correct.\n",
    " F1 Score: Good balance between precision and recall.\n",
    " Accuracy: 0.86 training accuracy means the model has learned patterns well in the training data. \n",
    "\n",
    " \n",
    " **Test set/Unseen data evaluation metric results:**\n",
    " \n",
    " Classification report:\n",
    " \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.42      0.58        43\n",
    "           1       0.76      0.99      0.86        80\n",
    "\n",
    "    accuracy                           0.79       123\n",
    "   macro avg       0.85      0.70      0.72       123\n",
    "weighted avg       0.83      0.79      0.76       123\n",
    "\n",
    "**Approval**\n",
    "\n",
    "High recall of 0.99 for approved loans\n",
    "F1 score of 0.86 for approved loans.\n",
    "Model was able to identify approved loans.\n",
    "\n",
    "**Rejection**\n",
    "\n",
    "Low recall of 0.42 for rejected loans - less 0 than 1 in the dataset. Model is only focusing on 1 and is not identifying 0 much.\n",
    "\n",
    "Balancing weight class may have solved this but was not tried. \n",
    "\n",
    "But the precision - proportion of correctly predicted cases out of the rejection predictions, is 0.95 which means when the model predicts correctly when it is actually predicting rejections.\n",
    "\n",
    "Difference between training accuracy(cross-validation) and testing accuracy is **0.86-0.79 = 0.07** ie 7 percent which is insignificant. Only a large gap between training and test accuracy means overfitting, usually more than 10 percent. So there is no overfitting in the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
